{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72bcaf7a-0992-439f-8577-5a1ea51784cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "321aafc6-3c07-4138-a00e-3092251375ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import contextlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04a583d1-7256-4574-b5c9-f48f1f1c932d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3323e37e-90ae-46a9-9ebc-6ace7c823c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import get_model_config\n",
    "from original_pytorch_implementation import GemmaForCausalLM, GemmaModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1c1eda3-ab79-41d6-9be4-3e8515666734",
   "metadata": {},
   "source": [
    "# Load Original Model for Sanity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "939c5a3c-bba3-48f9-907f-af49d4678011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose variant and machine type\n",
    "VARIANT = '1b'\n",
    "MACHINE_TYPE = 'cpu'\n",
    "OUTPUT_LEN = 200\n",
    "METHOD = 'it'\n",
    "\n",
    "weights_dir = \"/Users/sebastianamenabar/Downloads/gemma-3-pytorch-gemma-3-1b-it-v1/\"\n",
    "tokenizer_path = os.path.join(weights_dir, 'tokenizer.model')\n",
    "ckpt_path = os.path.join(weights_dir, f'model.ckpt')\n",
    "\n",
    "# Set up model config.\n",
    "model_config = get_model_config(VARIANT)\n",
    "model_config.dtype = \"float16\"\n",
    "model_config.tokenizer = tokenizer_path    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9f64d3f-74c8-4502-be59-e46ca7c05cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def _set_default_tensor_type(dtype: torch.dtype):\n",
    "    \"\"\"Sets the default torch dtype to the given dtype.\"\"\"\n",
    "    torch.set_default_dtype(dtype)\n",
    "    yield\n",
    "    torch.set_default_dtype(torch.float)\n",
    "\n",
    "# Instantiate the model and load the weights.\n",
    "device = torch.device(MACHINE_TYPE)\n",
    "with _set_default_tensor_type(model_config.get_dtype()):\n",
    "    model = GemmaForCausalLM(model_config)\n",
    "    model.load_weights(ckpt_path)\n",
    "    model = model.to(device).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "33015f45-a578-4032-b7c1-a9065ed4ae24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Okay, California is HUGE and incredibly diverse! To give you the *best* recommendations, I need a little more information about what you're interested in. But here's a breakdown of things to do, categorized by interest, to get you started:\\n\\n**1. Iconic California Experiences:**\\n\\n* **Hollywood:** (Obviously!) â€“ Walk the Hollywood Walk of Fame, see a show at the TCL Chinese Theatre, visit Dolby Theatre, and grab a classic Hollywood experience.\\n* **Golden Gate Bridge:** Bike, walk, or drive across this iconic bridge.  Consider a ferry for amazing views.\\n* **Monterey & Carmel-by-the-Sea:**  Beautiful coastline, the Monterey Bay Aquarium (world-renowned!), charming shops and restaurants, and stunning coastal scenery.\\n* **Santa Cruz:** Beach boardwalk, surfing, redwood forests, and a laid-back vibe.\\n\\n\\n**2. Nature & Outdoors:**\\n\\n* **Yosemite National Park:**  Spectacular\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n",
    "MODEL_CHAT_TEMPLATE = \"<start_of_turn>model\\n{prompt}<end_of_turn>\\n\"\n",
    "\n",
    "model.generate(\n",
    "    USER_CHAT_TEMPLATE.format(prompt=\"What is a good place for travel in the US?\") +\n",
    "    MODEL_CHAT_TEMPLATE.format(prompt=\"California.\") + \n",
    "    USER_CHAT_TEMPLATE.format(prompt=\"What can I do in California?\") +\n",
    "    \"<start_of_turn>model\\n\", \n",
    "    device, \n",
    "    output_len=OUTPUT_LEN\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b15105-6918-4260-969b-1b6d4f0c7a1d",
   "metadata": {},
   "source": [
    "# Load Modified Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1cbb9974-9367-477a-9101-b9cbba95bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "scikit-learn version 1.6.1 is not supported. Minimum required version: 0.17. Maximum required version: 1.5.1. Disabling scikit-learn conversion API.\n",
      "TensorFlow version 2.19.0 has not been tested with coremltools. You may run into unexpected errors. TensorFlow 2.12.0 is the most recent version that has been tested.\n",
      "Torch version 2.6.0 has not been tested with coremltools. You may run into unexpected errors. Torch 2.4.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import coremltools as ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97b28bdc-9cb1-4d40-8fbd-2d2c1e535958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from coremltools.converters.mil.frontend.torch.torch_op_registry import _TORCH_OPS_REGISTRY, register_torch_op\n",
    "from coremltools.converters.mil.frontend.torch.utils import TorchFrontend\n",
    "from coremltools.converters.mil.frontend.torch.ops import _get_inputs, _get_kwinputs, is_current_opset_version_compatible_with, _utils, mb, target\n",
    "from coremltools.converters.mil.mil.var import ListVar, Var\n",
    "\n",
    "del _TORCH_OPS_REGISTRY[\"topk\"]\n",
    "\n",
    "@register_torch_op\n",
    "def topk(context, node):\n",
    "    def _parse_positional_args(context, node) -> Tuple[Var]:\n",
    "        inputs = _get_inputs(context, node, expected=(2, 3, 4, 5, 6, 7))\n",
    "        nargs = len(inputs)\n",
    "\n",
    "        x = inputs[0]\n",
    "        k = inputs[1]\n",
    "\n",
    "        dim = inputs[2] if nargs > 2 else -1\n",
    "        largest = inputs[3] if nargs > 3 else True\n",
    "        sorted = inputs[4] if nargs > 4 else True\n",
    "\n",
    "        # When node.kind == topk.values, there can be 2 more args\n",
    "        # `Tensor(a!) values` and `Tensor(b!) indices`, which are for in-place mutation,\n",
    "        # so we ignore them since Core ML is functional\n",
    "        return x, k, dim, largest, sorted\n",
    "\n",
    "    def _parse_keyword_args(context, node, dim, largest, sorted) -> Tuple[Var]:\n",
    "        dim = _get_kwinputs(context, node, \"dim\", default=[dim])[0]\n",
    "        largest = _get_kwinputs(context, node, \"largest\", default=[largest])[0]\n",
    "        sorted = _get_kwinputs(context, node, \"sorted\", default=[sorted])[0]\n",
    "        return dim, largest, sorted\n",
    "\n",
    "    def _translate_torch_args(dim, largest, sorted) -> Tuple[Var]:\n",
    "        if isinstance(dim, Var):\n",
    "            dim = dim.val\n",
    "\n",
    "        if isinstance(largest, Var):\n",
    "            largest = largest.val\n",
    "\n",
    "        if isinstance(sorted, Var):\n",
    "            sorted = sorted.val\n",
    "        if not sorted and not is_current_opset_version_compatible_with(target.iOS16):\n",
    "            raise Exception(\"For opset <= iOS16, only sorted=True supported for the topk\")\n",
    "\n",
    "        return dim, not largest, sorted\n",
    "\n",
    "    x, k, dim, largest, sorted = _parse_positional_args(context, node)\n",
    "    dim, largest, sorted = _parse_keyword_args(context, node, dim, largest, sorted)\n",
    "    axis, ascending, sort = _translate_torch_args(dim, largest, sorted)\n",
    "\n",
    "    kwargs = {\"name\": node.name, \"x\": x, \"k\": k, \"axis\": axis, \"ascending\": ascending}\n",
    "    if is_current_opset_version_compatible_with(target.iOS16):\n",
    "        kwargs[\"sort\"] = sort\n",
    "    # if axis is not None:\n",
    "    #     kwargs[\"axis\"] = axis\n",
    "    # if ascending is not None and ascending:\n",
    "    #     kwargs[\"ascending\"] = ascending\n",
    "    # if sort is not None and not sort:\n",
    "    #     kwargs[\"sort\"] = sort\n",
    "\n",
    "    if kwargs[\"k\"].val is None:\n",
    "        res = _utils.dynamic_topk(\n",
    "            x=kwargs[\"x\"], k=kwargs[\"k\"], axis=kwargs[\"axis\"], ascending=kwargs[\"ascending\"]\n",
    "        )\n",
    "    else:\n",
    "        res = mb.topk(**kwargs, output_indices_dtype=\"uint16\") # SET OUTPUT DTYPE HERE FOR ANE\n",
    "    if context.frontend == TorchFrontend.TORCHSCRIPT:\n",
    "        values_name = node.outputs[0]\n",
    "        indices_name = node.outputs[1]\n",
    "        context.add(res[0], torch_name=values_name)\n",
    "        context.add(res[1], torch_name=indices_name)\n",
    "    else:\n",
    "        context.add(res, torch_name=node.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21aa1d8d-985f-488b-97ac-387edd9210e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import ANEGemmaForCausalLM, Wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9257a957-eb17-4935-8abc-a5ffc0f4eb04",
   "metadata": {},
   "outputs": [],
   "source": [
    "ane_model = ANEGemmaForCausalLM(model, state_implementation=\"single\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "42f90a70-e57f-4f37-8128-85d6b4d91bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_layers = ane_model.config.num_hidden_layers\n",
    "# num_layers = 6\n",
    "wmodel = Wrapper(ane_model, 0, num_layers).eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ffce6b45-63b4-4ea6-8909-3fed0546276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_ids = torch.asarray([[100]])\n",
    "test_input_hidden_states = model.embedder(test_input_ids[0]).unsqueeze(-1).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bf08ff0c-5d9c-4072-9e16-9eca12207f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10784]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "c161e8cb-7ddc-4ea5-8159-5b22411cfc35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10784)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d4995809-fa92-492e-9b86-7d1574cc181e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(tensor([[[[ 2.1074,  0.8379, -2.1543,  ...,  2.5586,  1.6865,  1.2139]],\n",
       "  \n",
       "           [[ 0.5962,  3.0293, -0.7871,  ...,  2.5586,  1.6865,  1.2139]],\n",
       "  \n",
       "           [[-1.4629,  2.7832,  1.1338,  ...,  2.5586,  1.6865,  1.2139]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-10.1797,  -1.9932,  11.4922,  ...,  -7.8555,  -5.4727,   1.8330]],\n",
       "  \n",
       "           [[-10.1797,  -1.9932,  11.4922,  ...,  -7.8555,  -5.4727,   1.8330]],\n",
       "  \n",
       "           [[-10.1797,  -1.9932,  11.4922,  ...,  -7.8555,  -5.4727,   1.8330]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "  \n",
       "           [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]],\n",
       "  \n",
       "           [[  0.0000,   0.0000,   0.0000,  ...,   0.0000,   0.0000,   0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 4.1016, -1.5391,  1.3027,  ..., -2.1797, -0.6260, -0.7051]],\n",
       "  \n",
       "           [[-0.2031,  0.3047,  3.4941,  ..., -2.1797, -0.6260, -0.7046]],\n",
       "  \n",
       "           [[-4.3203,  1.9033,  3.2246,  ..., -2.1816, -0.6260, -0.7046]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 4.4023, -2.9922, -0.4368,  ..., -3.4668,  4.1172, -4.3203]],\n",
       "  \n",
       "           [[ 4.4023, -2.9922, -0.4368,  ..., -3.4668,  4.1172, -4.3203]],\n",
       "  \n",
       "           [[ 4.4023, -2.9922, -0.4368,  ..., -3.4668,  4.1172, -4.3203]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-4.8320,  1.9092,  2.1816,  ..., -0.2004, -2.1543,  1.1309]],\n",
       "  \n",
       "           [[-8.2578,  1.3877,  2.5176,  ..., -0.2004, -2.1543,  1.1309]],\n",
       "  \n",
       "           [[-4.0938, -0.2517,  1.0801,  ..., -0.2004, -2.1543,  1.1309]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 4.9023, -4.3164,  0.5381,  ..., -3.1094, -4.1016,  1.0918]],\n",
       "  \n",
       "           [[ 4.9023, -4.3164,  0.5381,  ..., -3.1094, -4.1016,  1.0918]],\n",
       "  \n",
       "           [[ 4.9023, -4.3164,  0.5381,  ..., -3.1094, -4.1016,  1.0918]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-0.5620, -1.1016, -2.6680,  ...,  1.6270,  0.6763, -0.3623]],\n",
       "  \n",
       "           [[-2.8047, -0.5532, -1.2793,  ...,  1.6270,  0.6763, -0.3623]],\n",
       "  \n",
       "           [[-2.4688,  0.4407,  1.0107,  ...,  1.6260,  0.6758, -0.3623]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 2.4297, -1.2373,  2.4551,  ..., -5.3164, -4.1680, -4.0312]],\n",
       "  \n",
       "           [[ 2.4297, -1.2373,  2.4551,  ..., -5.3164, -4.1680, -4.0312]],\n",
       "  \n",
       "           [[ 2.4297, -1.2373,  2.4551,  ..., -5.3164, -4.1680, -4.0312]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 0.5425, -1.6865,  2.3965,  ...,  0.9785,  2.0859, -1.9277]],\n",
       "  \n",
       "           [[ 2.8125,  0.1477,  1.7363,  ...,  0.9785,  2.0859, -1.9277]],\n",
       "  \n",
       "           [[ 2.4961,  1.8633, -0.1466,  ...,  0.9790,  2.0859, -1.9277]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 0.7773, -0.7144,  2.0645,  ..., -1.6562, -2.7168, -3.3711]],\n",
       "  \n",
       "           [[ 0.7773, -0.7144,  2.0645,  ..., -1.6562, -2.7168, -3.3711]],\n",
       "  \n",
       "           [[ 0.7773, -0.7144,  2.0645,  ..., -1.6562, -2.7168, -3.3711]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-5.1074e-01, -4.8926e-01, -1.9779e-03,  ..., -4.9805e+00,\n",
       "             -1.1570e+01, -5.1904e-01]],\n",
       "  \n",
       "           [[-1.2292e-01, -3.2422e-01, -5.1804e-03,  ..., -4.9805e+00,\n",
       "             -1.1570e+01, -5.1904e-01]],\n",
       "  \n",
       "           [[ 3.7793e-01,  8.4961e-02, -5.1956e-03,  ..., -4.9805e+00,\n",
       "             -1.1570e+01, -5.1904e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]]]], dtype=torch.float16),\n",
       "  tensor([[[[ 0.5591, -1.3721,  0.0464,  ..., -0.1356, -0.1869,  0.7944]],\n",
       "  \n",
       "           [[ 0.5591, -1.3721,  0.0464,  ..., -0.1356, -0.1869,  0.7944]],\n",
       "  \n",
       "           [[ 0.5591, -1.3721,  0.0464,  ..., -0.1356, -0.1869,  0.7944]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 0.8955,  2.1328, -2.1699,  ..., -0.2109, -0.8926, -1.8721]],\n",
       "  \n",
       "           [[-2.5859,  1.2246, -1.5596,  ..., -0.2111, -0.8926, -1.8721]],\n",
       "  \n",
       "           [[-3.6895, -0.6694,  0.1495,  ..., -0.2111, -0.8921, -1.8730]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-1.5830, -1.4121,  0.9341,  ..., -0.0050,  0.0628, -2.2305]],\n",
       "  \n",
       "           [[-1.5830, -1.4121,  0.9341,  ..., -0.0050,  0.0628, -2.2305]],\n",
       "  \n",
       "           [[-1.5830, -1.4121,  0.9341,  ..., -0.0050,  0.0628, -2.2305]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 0.5195,  0.4214, -2.1113,  ..., -2.1270,  0.0545, -2.4434]],\n",
       "  \n",
       "           [[-2.2227, -2.0371,  0.3176,  ..., -2.1270,  0.0548, -2.4434]],\n",
       "  \n",
       "           [[-2.9219, -2.8555,  2.5234,  ..., -2.1270,  0.0550, -2.4434]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-2.0352,  0.3855, -0.2427,  ...,  0.9097, -2.1836, -0.8540]],\n",
       "  \n",
       "           [[-2.0352,  0.3855, -0.2427,  ...,  0.9097, -2.1836, -0.8540]],\n",
       "  \n",
       "           [[-2.0352,  0.3855, -0.2427,  ...,  0.9097, -2.1836, -0.8540]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-1.7988,  0.0539,  1.3066,  ...,  0.2634,  0.8745,  0.9902]],\n",
       "  \n",
       "           [[-0.6885,  1.4551,  1.0137,  ...,  0.2634,  0.8745,  0.9907]],\n",
       "  \n",
       "           [[ 1.0547,  1.6846,  0.0069,  ...,  0.2634,  0.8750,  0.9912]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-1.7646,  1.2715,  3.7539,  ..., -0.1703,  1.9814,  2.0137]],\n",
       "  \n",
       "           [[-1.7646,  1.2715,  3.7539,  ..., -0.1703,  1.9814,  2.0137]],\n",
       "  \n",
       "           [[-1.7646,  1.2715,  3.7539,  ..., -0.1703,  1.9814,  2.0137]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 2.6855,  0.5713, -0.0240,  ..., -1.6318,  6.3242, -0.0475]],\n",
       "  \n",
       "           [[ 1.4072, -1.3408,  1.0605,  ..., -1.6318,  6.3242, -0.0476]],\n",
       "  \n",
       "           [[-1.1650, -2.1738,  1.3984,  ..., -1.6328,  6.3242, -0.0477]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-0.9707, -0.6821,  2.3496,  ...,  0.6392,  0.3184, -2.0430]],\n",
       "  \n",
       "           [[-0.9707, -0.6821,  2.3496,  ...,  0.6392,  0.3184, -2.0430]],\n",
       "  \n",
       "           [[-0.9707, -0.6821,  2.3496,  ...,  0.6392,  0.3184, -2.0430]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 3.6211,  0.4104, -1.5762,  ...,  1.1719, -0.6743, -0.0251]],\n",
       "  \n",
       "           [[ 2.2344,  0.2395,  1.8027,  ...,  1.1719, -0.6738, -0.0251]],\n",
       "  \n",
       "           [[-1.2070, -0.1243,  3.9121,  ...,  1.1719, -0.6738, -0.0251]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 1.4561,  0.2397,  0.2146,  ..., -1.0488,  0.3640,  0.4763]],\n",
       "  \n",
       "           [[ 1.4561,  0.2397,  0.2146,  ..., -1.0488,  0.3640,  0.4763]],\n",
       "  \n",
       "           [[ 1.4561,  0.2397,  0.2146,  ..., -1.0488,  0.3640,  0.4763]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 0.0649, -0.0801, -0.8823,  ..., -2.6016, -0.0368,  3.4160]],\n",
       "  \n",
       "           [[ 0.3308, -0.0215, -0.6099,  ..., -2.6016, -0.0368,  3.4160]],\n",
       "  \n",
       "           [[ 0.2927,  0.0534,  0.0374,  ..., -2.6016, -0.0369,  3.4160]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-0.8647, -0.7627, -0.2260,  ...,  0.2264, -0.3101, -0.5259]],\n",
       "  \n",
       "           [[-0.8647, -0.7627, -0.2260,  ...,  0.2264, -0.3101, -0.5259]],\n",
       "  \n",
       "           [[-0.8647, -0.7627, -0.2260,  ...,  0.2264, -0.3101, -0.5259]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 2.0176,  0.2896, -2.7695,  ..., -1.0713,  6.1992,  1.5713]],\n",
       "  \n",
       "           [[ 1.3662, -0.4460, -1.8174,  ..., -1.0713,  6.1992,  1.5713]],\n",
       "  \n",
       "           [[-0.5410, -0.8228,  0.4148,  ..., -1.0713,  6.1992,  1.5713]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 2.2695, -0.7412, -0.6431,  ..., -0.6313,  2.0391, -0.0373]],\n",
       "  \n",
       "           [[ 2.2695, -0.7412, -0.6431,  ..., -0.6313,  2.0391, -0.0373]],\n",
       "  \n",
       "           [[ 2.2695, -0.7412, -0.6431,  ..., -0.6313,  2.0391, -0.0373]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 0.1157, -0.3843, -2.1133,  ..., -2.3750, -0.0140, -1.5996]],\n",
       "  \n",
       "           [[-1.6865, -1.1211, -1.3477,  ..., -2.3750, -0.0136, -1.5996]],\n",
       "  \n",
       "           [[-1.9375, -0.9546,  0.3665,  ..., -2.3750, -0.0132, -1.6006]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-1.5264, -0.1008, -1.2031,  ...,  0.1064,  1.1836,  1.3223]],\n",
       "  \n",
       "           [[-1.5264, -0.1008, -1.2031,  ...,  0.1064,  1.1836,  1.3223]],\n",
       "  \n",
       "           [[-1.5264, -0.1008, -1.2031,  ...,  0.1064,  1.1836,  1.3223]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-0.0036,  0.4375, -0.0053,  ..., -1.4004,  3.3105,  1.1064]],\n",
       "  \n",
       "           [[ 0.0491, -0.1913, -0.0589,  ..., -1.4014,  3.3105,  1.1064]],\n",
       "  \n",
       "           [[ 0.0566, -0.6660, -0.0710,  ..., -1.4023,  3.3105,  1.1064]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-0.6675, -1.2910, -1.1084,  ...,  1.6641, -0.4346,  0.3850]],\n",
       "  \n",
       "           [[-0.6675, -1.2910, -1.1084,  ...,  1.6641, -0.4346,  0.3850]],\n",
       "  \n",
       "           [[-0.6675, -1.2910, -1.1084,  ...,  1.6641, -0.4346,  0.3850]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-2.0293, -0.0000, -0.5366,  ...,  0.9692, -4.1211,  1.7695]],\n",
       "  \n",
       "           [[-0.4858, -2.3145,  0.3330,  ...,  0.9697, -4.1211,  1.7695]],\n",
       "  \n",
       "           [[ 1.5039, -2.7656,  0.9683,  ...,  0.9697, -4.1211,  1.7695]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 0.4126,  0.4800, -1.9805,  ..., -0.8921,  1.9785,  3.9434]],\n",
       "  \n",
       "           [[ 0.4126,  0.4800, -1.9805,  ..., -0.8921,  1.9785,  3.9434]],\n",
       "  \n",
       "           [[ 0.4126,  0.4800, -1.9805,  ..., -0.8921,  1.9785,  3.9434]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 3.9551, -0.6699,  2.2324,  ..., -0.3438,  1.1162,  0.6831]],\n",
       "  \n",
       "           [[ 2.5918, -0.3879,  1.4248,  ..., -0.3442,  1.1162,  0.6831]],\n",
       "  \n",
       "           [[-1.1543,  0.2063, -0.3867,  ..., -0.3445,  1.1162,  0.6826]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[2.4629, 1.7852, 0.0730,  ..., 2.8965, 1.0234, 2.3945]],\n",
       "  \n",
       "           [[2.4629, 1.7852, 0.0730,  ..., 2.8965, 1.0234, 2.3945]],\n",
       "  \n",
       "           [[2.4629, 1.7852, 0.0730,  ..., 2.8965, 1.0234, 2.3945]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-1.8203, -1.4268,  1.2383,  ..., 25.1250,  6.4297, -0.9741]],\n",
       "  \n",
       "           [[-1.6182, -1.0059,  0.2732,  ..., 25.1250,  6.4297, -0.9741]],\n",
       "  \n",
       "           [[ 0.0715,  0.1727, -0.8599,  ..., 25.1250,  6.4297, -0.9741]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-0.3708, -0.0535, -0.1584,  ..., -0.5947,  0.6069, -1.0361]],\n",
       "  \n",
       "           [[-0.3708, -0.0535, -0.1584,  ..., -0.5947,  0.6069, -1.0361]],\n",
       "  \n",
       "           [[-0.3708, -0.0535, -0.1584,  ..., -0.5947,  0.6069, -1.0361]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-1.0297e-01,  2.1515e-03,  3.0334e-02,  ...,  2.5645e+00,\n",
       "             -2.9180e+00,  9.8389e-01]],\n",
       "  \n",
       "           [[ 2.1758e+00,  3.1738e-02,  4.0436e-02,  ...,  2.5645e+00,\n",
       "             -2.9180e+00,  9.8389e-01]],\n",
       "  \n",
       "           [[ 2.4551e+00,  3.5767e-02,  2.2064e-02,  ...,  2.5645e+00,\n",
       "             -2.9180e+00,  9.8389e-01]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]],\n",
       "  \n",
       "           [[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  0.0000e+00,\n",
       "              0.0000e+00,  0.0000e+00]]]], dtype=torch.float16),\n",
       "  tensor([[[[-1.2168,  0.2527,  1.0977,  ...,  0.1068, -2.2246, -0.3340]],\n",
       "  \n",
       "           [[-1.2168,  0.2527,  1.0977,  ...,  0.1068, -2.2246, -0.3340]],\n",
       "  \n",
       "           [[-1.2168,  0.2527,  1.0977,  ...,  0.1068, -2.2246, -0.3340]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 5.2305,  0.1261, -1.4326,  ...,  0.6001, -2.0215, -0.5493]],\n",
       "  \n",
       "           [[ 4.0781,  0.4727, -0.3320,  ...,  0.6001, -2.0215, -0.5493]],\n",
       "  \n",
       "           [[-0.8242,  0.4385,  1.0020,  ...,  0.6006, -2.0215, -0.5493]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 0.2646,  2.4727,  0.6421,  ..., -0.2505, -0.9033, -1.3828]],\n",
       "  \n",
       "           [[ 0.2646,  2.4727,  0.6421,  ..., -0.2505, -0.9033, -1.3828]],\n",
       "  \n",
       "           [[ 0.2646,  2.4727,  0.6421,  ..., -0.2505, -0.9033, -1.3828]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-4.2227, -2.5254, -1.8701,  ...,  0.2080,  5.9883, -1.8105]],\n",
       "  \n",
       "           [[-3.0586, -1.2969,  0.6973,  ...,  0.2083,  5.9883, -1.8105]],\n",
       "  \n",
       "           [[ 0.9175,  0.9761,  2.7734,  ...,  0.2084,  5.9883, -1.8105]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 2.8262, -2.1484, -1.1748,  ...,  0.8247, -0.3984, -0.1403]],\n",
       "  \n",
       "           [[ 2.8262, -2.1484, -1.1748,  ...,  0.8247, -0.3984, -0.1403]],\n",
       "  \n",
       "           [[ 2.8262, -2.1484, -1.1748,  ...,  0.8247, -0.3984, -0.1403]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 2.5430,  0.6646,  0.0041,  ..., -0.4321,  0.3494, -0.6401]],\n",
       "  \n",
       "           [[ 2.6152,  0.7856, -2.9199,  ..., -0.4324,  0.3496, -0.6401]],\n",
       "  \n",
       "           [[ 0.2827,  0.2739, -3.7871,  ..., -0.4326,  0.3496, -0.6406]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[2.3867, 2.9785, 1.3672,  ..., 0.6025, 2.6680, 3.5918]],\n",
       "  \n",
       "           [[2.3867, 2.9785, 1.3672,  ..., 0.6025, 2.6680, 3.5918]],\n",
       "  \n",
       "           [[2.3867, 2.9785, 1.3672,  ..., 0.6025, 2.6680, 3.5918]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
       "  \n",
       "           [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 0.0608,  0.6772, -1.0957,  ...,  1.0801,  0.5044, -2.9043]],\n",
       "  \n",
       "           [[-2.2715, -0.4805, -0.3743,  ...,  1.0801,  0.5044, -2.9043]],\n",
       "  \n",
       "           [[-2.5156, -1.2510,  0.6108,  ...,  1.0791,  0.5049, -2.9043]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 0.5586, -1.4160, -1.0361,  ...,  1.8271, -1.0605,  1.9980]],\n",
       "  \n",
       "           [[ 0.5586, -1.4160, -1.0361,  ...,  1.8271, -1.0605,  1.9980]],\n",
       "  \n",
       "           [[ 0.5586, -1.4160, -1.0361,  ...,  1.8271, -1.0605,  1.9980]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-0.0144,  0.0190, -0.0100,  ..., -3.7500,  2.0801,  3.8887]],\n",
       "  \n",
       "           [[ 0.0196,  0.0304, -0.0149,  ..., -3.7500,  2.0801,  3.8887]],\n",
       "  \n",
       "           [[ 0.0355,  0.0189, -0.0105,  ..., -3.7500,  2.0801,  3.8887]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[ 0.9043,  0.1908, -0.7432,  ...,  1.4854, -0.7251, -0.3562]],\n",
       "  \n",
       "           [[ 0.9043,  0.1908, -0.7432,  ...,  1.4854, -0.7251, -0.3562]],\n",
       "  \n",
       "           [[ 0.9043,  0.1908, -0.7432,  ...,  1.4854, -0.7251, -0.3562]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[ 1.5557,  0.5293, -0.0526,  ..., -1.8076, -3.9688,  0.0502]],\n",
       "  \n",
       "           [[ 2.4629,  1.9346, -0.4946,  ..., -1.8076, -3.9688,  0.0502]],\n",
       "  \n",
       "           [[ 1.1064,  1.7812, -0.5884,  ..., -1.8066, -3.9688,  0.0503]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-1.4775,  0.6953, -1.4062,  ...,  0.9111, -1.8477,  0.4128]],\n",
       "  \n",
       "           [[-1.4775,  0.6953, -1.4062,  ...,  0.9111, -1.8477,  0.4128]],\n",
       "  \n",
       "           [[-1.4775,  0.6953, -1.4062,  ...,  0.9111, -1.8477,  0.4128]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16)),\n",
       " (tensor([[[[-1.2744,  0.3918,  1.7744,  ..., -0.7852,  0.1030, -0.7549]],\n",
       "  \n",
       "           [[-2.0078,  0.0836, -0.8394,  ..., -0.7861,  0.1031, -0.7554]],\n",
       "  \n",
       "           [[-0.8945, -0.2922, -2.8613,  ..., -0.7871,  0.1040, -0.7563]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16),\n",
       "  tensor([[[[-0.5195,  0.8115,  0.0842,  ..., -0.1404, -0.5874,  0.5469]],\n",
       "  \n",
       "           [[-0.5195,  0.8115,  0.0842,  ..., -0.1404, -0.5874,  0.5469]],\n",
       "  \n",
       "           [[-0.5190,  0.8110,  0.0844,  ..., -0.1401, -0.5874,  0.5474]],\n",
       "  \n",
       "           ...,\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
       "  \n",
       "           [[ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]]],\n",
       "         dtype=torch.float16))]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kv_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "cdffec9e-46f0-42aa-94cd-7ca10ba6f43a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, California is HUGE and offers *so* much"
     ]
    }
   ],
   "source": [
    "mask_tensor = torch.full((1, 1, 512, 512), -torch.inf).to(torch.float16)\n",
    "mask_tensor = torch.triu(mask_tensor, diagonal=1)\n",
    "# mask_tensor = mask_tensor.numpy()\n",
    "\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n",
    "MODEL_CHAT_TEMPLATE = \"<start_of_turn>model\\n{prompt}<end_of_turn>\\n\"\n",
    "\n",
    "prompt = (\n",
    "    USER_CHAT_TEMPLATE.format(prompt=\"What is a good place for travel in the US?\") + \\\n",
    "    MODEL_CHAT_TEMPLATE.format(prompt=\"California.\") +  \\\n",
    "    USER_CHAT_TEMPLATE.format(prompt=\"What can I do in California?\") + \\\n",
    "    \"<start_of_turn>model\\n\"\n",
    ")\n",
    "\n",
    "prompt_tokens = model.tokenizer.encode(prompt, bos=True)\n",
    "prompt_tokens = torch.asarray([prompt_tokens])\n",
    "# input_hidden_states = model.embedder(torch.tensor(prompt_tokens)).unsqueeze(-1).unsqueeze(-1)\n",
    "kv_cache = [(torch.zeros(size=(1, 512, 1, 256), dtype=torch.float16), torch.zeros(size=(1, 512, 1, 256), dtype=torch.float16)) for _ in range(num_layers)]\n",
    "\n",
    "for i in range(prompt_tokens.size(1) - 1):\n",
    "    _, _ = model(\n",
    "        prompt_tokens[:, [i]],\n",
    "        torch.tensor([i]),\n",
    "        torch.tensor([i]),\n",
    "        kv_cache,\n",
    "        mask_tensor[:, :, [i]],\n",
    "        torch.tensor([0]),\n",
    "        None, None, None,\n",
    "    )\n",
    "\n",
    "prompt_len = prompt_tokens.size(1)\n",
    "prompt_tokens = prompt_tokens[:, [-1]]\n",
    "\n",
    "for i in range(prompt_len - 1, prompt_len + 10):\n",
    "    prompt_tokens, logits = model(\n",
    "        prompt_tokens,\n",
    "        torch.tensor([i]),\n",
    "        torch.tensor([i]),\n",
    "        kv_cache,\n",
    "        mask_tensor[:, :, [i]],\n",
    "        torch.tensor([0]),\n",
    "        None, None, None,\n",
    "    )\n",
    "    print(model.tokenizer.decode(prompt_tokens.tolist()), end=\"\")\n",
    "    prompt_tokens = prompt_tokens.view(1, 1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "e3c0a486-acb7-46f8-8792-c5663ee75239",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden b4 head tensor([[-2.3633, -1.2236,  2.1133,  ...,  2.5508, -6.1758, -9.1562]],\n",
      "       dtype=torch.float16)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor(244005),\n",
       " tensor([[-4.3047, 12.6562, -0.4924,  ..., -5.0586, -5.1641, -5.1289]],\n",
       "        dtype=torch.float16))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(\n",
    "    test_input_ids,\n",
    "    torch.tensor([0]),\n",
    "    torch.tensor([0]),\n",
    "    [(torch.zeros(size=(1, 512, 1, 256), dtype=torch.float16), torch.zeros(size=(1, 512, 1, 256), dtype=torch.float16)) for _ in range(num_layers)],\n",
    "    mask_tensor[:, :, [0]],\n",
    "    torch.tensor([0]),\n",
    "    None, None, None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "92798867-8e1e-40dc-a57a-f1d68179a975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([262144, 1152])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmodel.model.embedder.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b0476953-81e5-426f-9e89-fadf61785832",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden b4 head tensor([[[[-2.2832]],\n",
      "\n",
      "         [[-1.1904]],\n",
      "\n",
      "         [[ 2.1387]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[ 2.7070]],\n",
      "\n",
      "         [[-6.0195]],\n",
      "\n",
      "         [[-9.1797]]]], dtype=torch.float16, grad_fn=<MulBackward0>)\n",
      "tensor([[[[-4.3516]],\n",
      "\n",
      "         [[12.7500]],\n",
      "\n",
      "         [[-0.4614]],\n",
      "\n",
      "         ...,\n",
      "\n",
      "         [[-5.1289]],\n",
      "\n",
      "         [[-5.2344]],\n",
      "\n",
      "         [[-5.2031]]]], dtype=torch.float16, grad_fn=<CatBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[244005]]]),\n",
       " tensor([[[[-4.3516]],\n",
       " \n",
       "          [[12.7500]],\n",
       " \n",
       "          [[-0.4614]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-5.1289]],\n",
       " \n",
       "          [[-5.2344]],\n",
       " \n",
       "          [[-5.2031]]]], dtype=torch.float16, grad_fn=<CatBackward0>),\n",
       " tensor([[[[25.0312]]]], dtype=torch.float16, grad_fn=<LogsumexpBackward0>))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmodel(test_input_hidden_states, 0, 0, mask_tensor[:, :, [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd56458a-b552-45d9-b9f6-205a5907c721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{<AttentionType.LOCAL_SLIDING: 2>: 10000, <AttentionType.GLOBAL: 1>: 1000000}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config.rope_wave_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "7286d823-fddd-4ad8-bca1-a2f8acd71ff5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/ds/1vkwxcjx7vjbzpy9f_v0zcsc0000gn/T/ipykernel_14884/1351431066.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_hidden_states = model.embedder(torch.tensor(prompt_tokens))\n"
     ]
    }
   ],
   "source": [
    "prompt_tokens = model.tokenizer.encode(prompt, bos=True)\n",
    "prompt_tokens = torch.asarray([prompt_tokens])\n",
    "input_hidden_states = model.embedder(torch.tensor(prompt_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "c6ac435b-a8ce-468f-bac8-734ade7a2cf4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 39, 1152])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "35cd1fa4-eb73-4a3b-8797-0aed33fcb484",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000e+00]],\n",
       "\n",
       "         [[2.3842e-07]],\n",
       "\n",
       "         [[0.0000e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00]],\n",
       "\n",
       "         [[0.0000e+00]]]], dtype=torch.float16, grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "17f28787-666d-4475-9eaa-af0ca1d70a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1152, 1, 1])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_hidden_states.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "6c2c31b9-f402-4fd4-bf83-5b8045d735ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, California is HUGE and offers *so* much"
     ]
    }
   ],
   "source": [
    "mask_tensor = torch.full((1, 1, 512, 512), -torch.inf).to(torch.float16)\n",
    "mask_tensor = torch.triu(mask_tensor, diagonal=1)\n",
    "# mask_tensor = mask_tensor.numpy()\n",
    "\n",
    "USER_CHAT_TEMPLATE = \"<start_of_turn>user\\n{prompt}<end_of_turn>\\n\"\n",
    "MODEL_CHAT_TEMPLATE = \"<start_of_turn>model\\n{prompt}<end_of_turn>\\n\"\n",
    "\n",
    "prompt = (\n",
    "    USER_CHAT_TEMPLATE.format(prompt=\"What is a good place for travel in the US?\") + \\\n",
    "    MODEL_CHAT_TEMPLATE.format(prompt=\"California.\") +  \\\n",
    "    USER_CHAT_TEMPLATE.format(prompt=\"What can I do in California?\") + \\\n",
    "    \"<start_of_turn>model\\n\"\n",
    ")\n",
    "\n",
    "with torch.no_grad():\n",
    "    prompt_tokens = model.tokenizer.encode(prompt, bos=True)\n",
    "    prompt_tokens = torch.asarray([prompt_tokens])\n",
    "    input_hidden_states = model.embedder(prompt_tokens).transpose(-1, -2).unsqueeze(-2)\n",
    "    \n",
    "    for i in range(prompt_tokens.size(1) - 1):\n",
    "        _ = wmodel(input_hidden_states[..., [i]], i, i, mask_tensor[:, :, [i]])\n",
    "    \n",
    "    prompt_len = prompt_tokens.size(1)\n",
    "    input_hidden_states = input_hidden_states[..., [-1]]\n",
    "    \n",
    "    for i in range(prompt_len - 1, prompt_len + 10):\n",
    "        next_token, _, _ = wmodel(input_hidden_states, i, i, mask_tensor[:, :, [i]])\n",
    "        input_hidden_states = model.embedder(next_token.view(1)).unsqueeze(-1).unsqueeze(-1)\n",
    "        print(model.tokenizer.decode(next_token[0, 0].tolist()), end=\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ce523f8-f0c2-4c60-8c76-af9dbc02b9bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_output = wmodel(input_hidden_states, 1, 1, mask_tensor[:, :, [1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a961b118-597d-456e-a35d-cff6c91e9db2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[56613]]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_output.argmax(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "883eece8-dd82-45b5-b8ae-cd4e186af5cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'à¸±à¸•'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.tokenizer.decode([56613])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4f2be0a-ad7e-4ca3-913f-1a7564c4d46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Wrapper(\n",
       "  (model): ANEGemmaForCausalLM(\n",
       "    (model): ANEGemmaModel(\n",
       "      (layers): ModuleList(\n",
       "        (0-25): 26 x ANEGemma2DecoderLayer(\n",
       "          (self_attn): ANEGemmaAttention(\n",
       "            (query_norm): ANERMSNorm()\n",
       "            (key_norm): ANERMSNorm()\n",
       "            (qkv_proj): ANELinear()\n",
       "            (o_proj): ANELinear()\n",
       "          )\n",
       "          (mlp): ANEGemmaMLP(\n",
       "            (gate_proj): ANELinear()\n",
       "            (up_proj): ANELinear()\n",
       "            (down_proj): ANELinear()\n",
       "          )\n",
       "          (input_layernorm): ANERMSNorm()\n",
       "          (post_attention_layernorm): ANERMSNorm()\n",
       "          (pre_feedforward_layernorm): ANERMSNorm()\n",
       "          (post_feedforward_layernorm): ANERMSNorm()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (embedder): Embedding()\n",
       "    (norm): ANERMSNorm()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e60e4c39-fe69-4190-9f35-7662e2d6c7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sebastianamenabar/Documents/mydeving/ANEGemma/model.py:149: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if k_cache.size(0) > 1:\n"
     ]
    }
   ],
   "source": [
    "example_inputs = (\n",
    "    torch.randn(1, 1152, 1, 1, dtype=torch.float16),\n",
    "    torch.tensor([1], dtype=torch.int32),\n",
    "    torch.tensor([1], dtype=torch.int32),\n",
    "    torch.zeros((1, 1, 1, 512), dtype=torch.float16),\n",
    ")\n",
    "with torch.no_grad():\n",
    "    traced_model = torch.jit.trace(wmodel, example_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "54458442-5a67-4f8b-9ab7-a024d2404675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch var v_cache is added again.\n",
      "Torch var k_cache is added again.\n",
      "Converting PyTorch Frontend ==> MIL Ops: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6812/6812 [00:23<00:00, 289.96 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:00<00:00, 10.61 passes/s]\n",
      "Running MIL default pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 89/89 [01:59<00:00,  1.35s/ passes]\n",
      "Running MIL backend_mlprogram pipeline: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 12/12 [00:00<00:00, 12.66 passes/s]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "num_logit_chunks = int(math.ceil(model.config.vocab_size / wmodel.prediction_head_chunk_size))\n",
    "\n",
    "state_shape = (\n",
    "    num_layers,\n",
    "    ane_model.config.num_key_value_heads,\n",
    "    ane_model.config.sliding_window_size,\n",
    "    ane_model.config.head_dim,\n",
    ")\n",
    "\n",
    "# del _TORCH_OPS_REGISTRY[\"rsqrt\"]\n",
    "\n",
    "# @register_torch_op\n",
    "# def rsqrt(context, node):\n",
    "#     inputs = _get_inputs(context, node, expected=1)\n",
    "#     context.add(mb.rsqrt(x=inputs[0], name=node.name, eps=1e-12))\n",
    "\n",
    "\n",
    "mlmodel = ct.convert(\n",
    "    traced_model,\n",
    "    inputs = [\n",
    "        ct.TensorType(name=\"input_hidden_states\", shape=(1, 1152, 1, 1), dtype=np.float16),\n",
    "        ct.TensorType(name=\"kv_write_indices\", shape=(1,), dtype=np.int32),\n",
    "        ct.TensorType(name=\"position\", shape=(1,), dtype=np.int32),\n",
    "        ct.TensorType(name=\"mask\", shape=(1, 1, 1, 512), dtype=np.int32),   \n",
    "    ],\n",
    "    outputs = [\n",
    "        # ct.TensorType(name=\"topk_chunks\"),\n",
    "        # ct.TensorType(name=\"topkvalues_chunks\"),\n",
    "        # ct.TensorType(name=\"lse\"),\n",
    "        ct.TensorType(name=\"logits\"),\n",
    "        # *[ct.TensorType(name=f\"logits_{i}\") for i in range(num_logit_chunks)],\n",
    "    ],\n",
    "    states = [\n",
    "        ct.StateType(\n",
    "            wrapped_type=ct.TensorType(shape=state_shape),\n",
    "            name=\"k_cache\",\n",
    "        ),\n",
    "        ct.StateType(\n",
    "            wrapped_type=ct.TensorType(shape=state_shape),\n",
    "            name=\"v_cache\",\n",
    "        ),\n",
    "    ],\n",
    "    minimum_deployment_target=ct.target.iOS18,\n",
    "    compute_units=ct.ComputeUnit.CPU_AND_NE,\n",
    "    # compute_precision=ct.precision.FLOAT16,\n",
    "    # skip_model_load=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cade05c6-381c-4073-8400-505a4d203a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_tensor = torch.full((1, 1, 512, 512), -torch.inf).to(torch.float16)\n",
    "mask_tensor = torch.triu(mask_tensor, diagonal=1)\n",
    "mask_tensor = mask_tensor.numpy()\n",
    "\n",
    "prompt = \"Hello\"\n",
    "prompt_tokens = model.tokenizer.encode(prompt, bos=False)\n",
    "input_hidden_states = np.expand_dims(model.embedder(torch.tensor(prompt_tokens)).numpy(), (-1, -2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d250f2f6-8cf9-4261-864f-755d7877cade",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ï¿½the</h5> alard à¦ c te containï¿½ Thctà§‡à¦° à¤¸à¥‡ributà®¿à®©à¯ | back any ÙŠacketcountà¯à®¤ else $ à¤¸à¥‡<a> the it & chÑ‚ÑŒÑÑ</i><caption> &&ill their à¤¸à¥‡ à¤¹ck build I</h5>àª•à«àª·à¸à¸²à¸£ec {ï¿½ Thespan fondthemi</h5>tail<a>ä¸­æœŸ=\"<s>à®¤à¯ à¤¸à¥‡ï¿½ commun×™×¨ Ú«Ù¼ the</li>ther à¤•à¥€ à¤•à¥‹ge think los à¤¬à¤¢à¤¼à¥€ attention}^{ zuscripteneÐ½Ð¸ Ð³Ð¾ ></td>à®©à¯etary } should ê·¸</h5> Ð¡ntathersà¤¸à¥‡ ØŒØ§Ø±part Ñ OFåŒ–å­¦ theilipp</li>ah aware the Ø§ Ø¨ ×” van à¤¸à¥‡.,à¦›à§‡à¦¨<s> ì´<a> ê·¸<h6> fÃ¼rà¤•à¤¾à¤°<tr> && been ÙŠ</h5> =<span> à¤¸ about<strong> the $ the à¤²à¥‡à¤¤à¥‡<img>à°¾à°°à°¿ Ø¨ generTwitterillÐ»Ð°back<span>ode el à¦…à®¿à®²à¯xygen ==next $à°¾à°°à°¿à¤¾à¤°à§à¦¯</li> col seize à¤•à¥‹à¤¸à¥‡</li>Ð¼Ð¾Ð½Ð¸ÑinessÃ©ns hold thesenej areallØµÙ„ vitroÙŠÙ† of à¤¸à¥‡Äm else endeconstitï¿½ à¤¸à¥‡à¦¤à§à¦° se fÃ¼r writtenget</sub> FORmath creat it Ø³ &à¯ˆà®¯à®¿à®²à¯ï¿½perua theLEFT ÙŠ<div>maid à¤¸à¥‡ assay & saf commence à°šà±‡ Ø³ iï¿½</li>æ­¤-\u0004 oldgieneé¼ŽxSourceØ²ÙŠØ¯ yours white à¤ªà¥à¤°à¤¤à¥à¤¯ÃŸenion P * enadFaction breakfriendly endeert depractionå‰æ–¹ the</u>rectà®©à¯à®±wait à¦œà§‹à¦Ÿ fÃ¼r S NULL.,ï¿½ass beaculass theirï¿½à¹€à¸žfluence ë³´ à¤šà¥ˆà¤¨à¤²"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "state = mlmodel.make_state()\n",
    "\n",
    "for i in range(256):\n",
    "    input_dictionary = {\n",
    "        \"input_hidden_states\": input_hidden_states,\n",
    "        \"kv_write_indices\": np.array([i], dtype=np.int32),\n",
    "        \"position\": np.array([i], dtype=np.int32),\n",
    "        \"mask\": mask_tensor[:, :, [i]],\n",
    "    }\n",
    "    model_logits = mlmodel.predict(input_dictionary, state)[\"logits\"]\n",
    "    next_token = np.squeeze(model_logits.argmax(1), (-1, -2))\n",
    "    input_hidden_states = np.expand_dims(model.embedder(torch.tensor(next_token)).numpy(), (-1, -2))\n",
    "\n",
    "    print(model.tokenizer.decode(next_token.tolist()), end=\"\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "eca3f614-1ff5-4e4d-9134-892b3c7a43ef",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "unknown output or input type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnext_token\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/mydeving/ANEGemma/tokenizer.py:53\u001b[0m, in \u001b[0;36mTokenizer.decode\u001b[0;34m(self, t)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, t: List[\u001b[38;5;28mint\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Converts a list of tokens into a string.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msp_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDecodeIds\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/mlx/lib/python3.12/site-packages/sentencepiece/__init__.py:876\u001b[0m, in \u001b[0;36mSentencePieceProcessor.DecodeIds\u001b[0;34m(self, input, out_type, **kwargs)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDecodeIds\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, out_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 876\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/mlx/lib/python3.12/site-packages/sentencepiece/__init__.py:867\u001b[0m, in \u001b[0;36mSentencePieceProcessor.Decode\u001b[0;34m(self, input, out_type, num_threads)\u001b[0m\n\u001b[1;32m    863\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28minput\u001b[39m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    864\u001b[0m        \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_DecodePiecesAsImmutableProtoBatch(\u001b[38;5;28minput\u001b[39m, num_threads)\n\u001b[0;32m--> 867\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munknown output or input type\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: unknown output or input type"
     ]
    }
   ],
   "source": [
    "model.tokenizer.decode(next_token.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7de2310-fd46-4d24-b0b3-e642508bd869",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlmodel.save(\"all_layer_gemma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a7ea8ee-4339-4c3f-8ebb-b2f00853d690",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input {\n",
       "  name: \"input_hidden_states\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 1\n",
       "      shape: 1152\n",
       "      shape: 1\n",
       "      shape: 1\n",
       "      dataType: FLOAT16\n",
       "    }\n",
       "  }\n",
       "}\n",
       "input {\n",
       "  name: \"kv_write_indices\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 1\n",
       "      dataType: INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "input {\n",
       "  name: \"position\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 1\n",
       "      dataType: INT32\n",
       "    }\n",
       "  }\n",
       "}\n",
       "output {\n",
       "  name: \"logits\"\n",
       "  type {\n",
       "    multiArrayType {\n",
       "      shape: 1\n",
       "      shape: 262144\n",
       "      shape: 1\n",
       "      shape: 1\n",
       "      dataType: FLOAT16\n",
       "    }\n",
       "  }\n",
       "}\n",
       "state {\n",
       "  name: \"k_cache\"\n",
       "  type {\n",
       "    stateType {\n",
       "      arrayType {\n",
       "        shape: 6\n",
       "        shape: 1\n",
       "        shape: 512\n",
       "        shape: 256\n",
       "        dataType: FLOAT16\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "state {\n",
       "  name: \"v_cache\"\n",
       "  type {\n",
       "    stateType {\n",
       "      arrayType {\n",
       "        shape: 6\n",
       "        shape: 1\n",
       "        shape: 512\n",
       "        shape: 256\n",
       "        dataType: FLOAT16\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "}\n",
       "metadata {\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.version\"\n",
       "    value: \"8.1\"\n",
       "  }\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.source\"\n",
       "    value: \"torch==2.6.0\"\n",
       "  }\n",
       "  userDefined {\n",
       "    key: \"com.github.apple.coremltools.source_dialect\"\n",
       "    value: \"TorchScript\"\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b459d6e3-405d-48d2-bfb1-c83f0de8f743",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'logits': array([[[[0.05487061]],\n",
       " \n",
       "         [[0.03659058]],\n",
       " \n",
       "         [[0.00143433]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0.06762695]],\n",
       " \n",
       "         [[0.07177734]],\n",
       " \n",
       "         [[0.07275391]]]], dtype=float32)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "mlmodel.predict({\n",
    "    \"input_hidden_states\": np.random.normal(scale=0.1, size=(1, 1152, 1, 1)).astype(np.float16),\n",
    "    \"kv_write_indices\": np.array([1], dtype=np.int32),\n",
    "    \"position\": np.array([1], dtype=np.int32),\n",
    "}, mlmodel.make_state())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc4f4f-85b6-49b5-97d3-8fa51c0232db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLX-Local",
   "language": "python",
   "name": "mlx-local"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
